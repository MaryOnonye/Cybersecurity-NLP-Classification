{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb02528762c76e63",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c32a5",
   "metadata": {},
   "source": [
    "# DeBERTa Hyperparameter Tuning â€“ Cybersecurity News Classification\n",
    "\n",
    "## Objective\n",
    "Tune key training hyperparameters for a fine-tuned DeBERTa model to improve classification performance on cybersecurity threat categories.\n",
    "\n",
    "## What this notebook covers\n",
    "- Hyperparameters explored (learning rate, batch size, epochs, weight decay)\n",
    "- Training runs and comparison logic\n",
    "- Metric tracking (F1, precision/recall)\n",
    "- Best-configuration selection\n",
    "\n",
    "## Output\n",
    "A selected hyperparameter configuration with performance results and rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df3df996700ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:01.106504Z",
     "start_time": "2025-12-08T20:29:49.888151Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, DebertaV2ForSequenceClassification, AutoConfig\n",
    "from datasets import DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc49713f6d5a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:49:24.200002Z",
     "start_time": "2025-12-09T01:49:24.044690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in tokenized datasets\n",
    "tokenized = DatasetDict.load_from_disk('../processed/tokenized_DeBERTa_ds')\n",
    "\n",
    "train_tokenized = tokenized['train']\n",
    "val_tokenized = tokenized['validation']\n",
    "test_tokenized = tokenized['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0a8fcea08ab27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:02.544532Z",
     "start_time": "2025-12-08T20:30:01.166098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5b5388b94c508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:02.700842Z",
     "start_time": "2025-12-08T20:30:02.692797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload label mappings\n",
    "with open('../processed/label2id.json') as f:\n",
    "    label2id = json.load(f)\n",
    "with open('../processed/id2label.json') as f:\n",
    "    id2label = json.load(f)\n",
    "num_labels = len(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976236245994b9d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:02.732112Z",
     "start_time": "2025-12-08T20:30:02.712419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create focal loss class for better classification for imbalanced classes\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none', weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class DebertaForFocalLoss(DebertaV2ForSequenceClassification):\n",
    "    def __init__(self, config, gamma=2.0, class_weights=None):\n",
    "        super().__init__(config)\n",
    "        self.focal = FocalLoss(gamma=gamma, weight=class_weights)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Call DeBERTa forward WITHOUT passing labels\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=None,   # disable internal CE-loss\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.focal(logits, labels)\n",
    "\n",
    "        # HuggingFace Trainer needs outputs.loss\n",
    "        return {\"loss\": loss, \"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969dee37cdffc6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:02.748458Z",
     "start_time": "2025-12-08T20:30:02.739337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create evaluation metrics function for trainer\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc489b224033e251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:03.450848Z",
     "start_time": "2025-12-08T20:30:02.763735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and add class weights\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "y_train = np.array(train_tokenized['labels'], dtype=int)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "class_weights_np = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "print('Class weights:', class_weights_np)\n",
    "\n",
    "class_weights = torch.tensor(class_weights_np, dtype=torch.float).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b8adb11bca0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:03.481591Z",
     "start_time": "2025-12-08T20:30:03.468420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create function to reinitialize a new model on each hyperparam tune\n",
    "def model_init():\n",
    "    # Load config\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        \"microsoft/deberta-v3-base\",\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    # Recreate model with custom class\n",
    "    model = DebertaForFocalLoss.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        config=config,\n",
    "        class_weights=class_weights,\n",
    "        gamma=2.0\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857261b0777f529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:03.586619Z",
     "start_time": "2025-12-08T20:30:03.489255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create baseline training arguments for tuning\n",
    "base_args = TrainingArguments(\n",
    "    output_dir='../models/tuning_outputs',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    logging_steps=50,\n",
    "    logging_strategy='steps',\n",
    "\n",
    "    fp16=False,\n",
    "    bf16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686215bd0e0c54e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:04.606648Z",
     "start_time": "2025-12-08T20:30:03.596106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build trainer\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=base_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c53981ff7929f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T20:30:04.888471Z",
     "start_time": "2025-12-08T20:30:04.861501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparam tuning grid\n",
    "def hp_grid(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 2e-5, 3e-5]),\n",
    "        'num_train_epochs': trial.suggest_categorical('num_train_epochs', [3, 4, 5]),\n",
    "        'warmup_ratio': trial.suggest_categorical('warmup_ratio', [0.0, 0.1]),\n",
    "        'weight_decay': trial.suggest_categorical('weight_decay', [0.01, 0.05])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edc143c7a34ffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:05:29.070799Z",
     "start_time": "2025-12-08T20:30:04.900108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run tuner\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction='maximize',\n",
    "    hp_space=hp_grid,\n",
    "    n_trials=12\n",
    ")\n",
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac05c83b4c6908b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28e7f424ea2704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:05:29.749481Z",
     "start_time": "2025-12-09T00:05:29.718096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "# {'learning_rate': 1e-05,\n",
    "#  'num_train_epochs': 4,\n",
    "#  'warmup_ratio': 0.0,\n",
    "#  'weight_decay': 0.05}\n",
    "best_run.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00fb34cd7f99c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:05:29.860624Z",
     "start_time": "2025-12-09T00:05:29.849003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign variables for best params\n",
    "best_lr = best_run.hyperparameters['learning_rate']\n",
    "best_epochs = best_run.hyperparameters['num_train_epochs']\n",
    "best_decay = best_run.hyperparameters['weight_decay']\n",
    "best_warmup = best_run.hyperparameters['warmup_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1ee2486ddf06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:05:30.034804Z",
     "start_time": "2025-12-09T00:05:29.912065Z"
    }
   },
   "outputs": [],
   "source": [
    "# build train arguments with tuned parameters\n",
    "final_args = TrainingArguments(\n",
    "    output_dir=\"../models/DeBERTa_tuned\",\n",
    "    learning_rate=best_lr,\n",
    "    num_train_epochs=best_epochs,\n",
    "    weight_decay=best_decay,\n",
    "    warmup_ratio=best_warmup,\n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    logging_steps=50,\n",
    "    fp16=False,\n",
    "    bf16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a08ec9bf25e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:18:55.255816Z",
     "start_time": "2025-12-09T00:05:30.048036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and save final model\n",
    "final_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=final_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "final_trainer.train()\n",
    "final_trainer.save_model(\"../models/DeBERTa_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b63d6908046db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:02:42.934353Z",
     "start_time": "2025-12-09T02:02:27.097886Z"
    }
   },
   "outputs": [],
   "source": [
    "# simple eval metrics\n",
    "final_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bf74d1fcb867a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:52:44.310392Z",
     "start_time": "2025-12-09T06:52:44.299749Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import concatenate_datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188ba1694fef725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:04:58.787385Z",
     "start_time": "2025-12-09T02:04:58.741931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cyber punk theme for charts\n",
    "plt.style.use('default')\n",
    "\n",
    "# Global dictionary\n",
    "plt.rcParams.update({\n",
    "    # Canvas and axes\n",
    "    'figure.facecolor': 'black',\n",
    "    'axes.facecolor': '#0d0d0d',\n",
    "    'axes.edgecolor': 'white',\n",
    "    'axes.labelcolor': 'white',\n",
    "    'axes.titlecolor': 'white',\n",
    "\n",
    "    # Tick appearance\n",
    "    'xtick.color': 'white',\n",
    "    'ytick.color': 'white',\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "\n",
    "    # Grid\n",
    "    'axes.grid': True,\n",
    "    'grid.color': '#333333',\n",
    "    'grid.linestyle': '--',\n",
    "    'grid.linewidth': 0.4,\n",
    "\n",
    "    # Line colors\n",
    "    'axes.prop_cycle': plt.cycler(color=[\n",
    "        '#ff2e2e',  \n",
    "        '#00eaff',  \n",
    "        '#40ffb3',  \n",
    "        '#ff9f1c', \n",
    "        '#d11aff'  \n",
    "    ]),\n",
    "\n",
    "    # Text\n",
    "    'text.color': 'white',\n",
    "\n",
    "    # Legend\n",
    "    'legend.facecolor': '#1a1a1a',\n",
    "    'legend.edgecolor': 'white',\n",
    "    'legend.fontsize': 10,\n",
    "\n",
    "    # Lines\n",
    "    'lines.linewidth': 2.0,\n",
    "    'lines.markersize': 6,\n",
    "\n",
    "\n",
    "    'savefig.facecolor': 'black',\n",
    "    'savefig.edgecolor': 'black',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fc56c0f9b8056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:12:21.501774Z",
     "start_time": "2025-12-09T02:12:21.455201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge validation and training set for last test evaluation\n",
    "full_train = concatenate_datasets([train_tokenized, val_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3da00db604fb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:14:58.091703Z",
     "start_time": "2025-12-09T02:14:58.084155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check best params\n",
    "best_run.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025078a773632bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:19:27.076458Z",
     "start_time": "2025-12-09T02:19:26.896760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create production args with tuned params\n",
    "production_args = TrainingArguments(\n",
    "    output_dir='../models/DeBERTa_production',\n",
    "    learning_rate=best_lr,\n",
    "    num_train_epochs=best_epochs,\n",
    "    weight_decay=best_decay,\n",
    "    warmup_ratio=best_warmup,\n",
    "\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "\n",
    "    logging_steps=50,\n",
    "    fp16=False,\n",
    "    bf16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae299a6c8842c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T02:42:37.362253Z",
     "start_time": "2025-12-09T02:42:35.866702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set production trainer params\n",
    "production_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=production_args,\n",
    "    train_dataset=full_train,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfdabbdb3507a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:30:38.690969Z",
     "start_time": "2025-12-09T02:43:33.204059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train prod model\n",
    "production_trainer.train()\n",
    "production_trainer.save_model('../models/DeBERTa_production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74ccb076f8a0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:50:26.765781Z",
     "start_time": "2025-12-09T06:48:38.204123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions for the model\n",
    "prod_output = production_trainer.predict(test_tokenized)\n",
    "\n",
    "logits = prod_output.predictions\n",
    "y_pred = logits.argmax(axis=1)\n",
    "y_true = prod_output.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f789fc27fbe70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T06:50:30.842788Z",
     "start_time": "2025-12-09T06:50:30.785843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print out test metrics\n",
    "print('Test Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print('Test F1 - Macro:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Test F1 - Weighted:', f1_score(y_true, y_pred, average='weighted'))\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d80f81e309ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:04:09.293515Z",
     "start_time": "2025-12-09T07:04:08.959768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot test per class confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='.2f', cmap='viridis',\n",
    "    xticklabels=id2label.values(),\n",
    "    yticklabels=id2label.values()\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix: Test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97872b520eeec0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T07:48:35.098440Z",
     "start_time": "2025-12-09T07:48:34.365164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot per class eval metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred, zero_division=0\n",
    ")\n",
    "\n",
    "labels = list(id2label.values())\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x - width, precision, width, label=\"Precision\")\n",
    "plt.bar(x, recall, width, label=\"Recall\")\n",
    "plt.bar(x + width, f1, width, label=\"F1\")\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Per Class Precision, Recall, and F1: Test-set\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
